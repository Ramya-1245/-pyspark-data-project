{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9966f26f-23b1-452a-a110-975ff6d6f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bc44ff-e393-4e68-8e37-1ad234868bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/30 16:03:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1641ba7e-b07a-4ca4-b16b-18da3b3e36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bc6698-6c45-43f5-9f13-9942f613c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de538001-6c65-435c-ab11-2646ec14a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85036c1-aa09-49c4-b8f3-4baa85fc5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_df = spark.createDataFrame([\n",
    "    (0, 'Hi I heard about spark'),\n",
    "    (1, 'I wish java could use case classes'),\n",
    "    (2, 'Logestic,regression,model,are,neat'),    \n",
    "],['Id', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74c1754-1052-42e7-b9d9-1fe996bf65ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| Id|            sentence|\n",
      "+---+--------------------+\n",
      "|  0|Hi I heard about ...|\n",
      "|  1|I wish java could...|\n",
      "|  2|Logestic,regressi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e057e85c-9835-45f3-800f-4c81e8aeb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| Id|            sentence|\n",
      "+---+--------------------+\n",
      "|  0|Hi I heard about ...|\n",
      "|  1|I wish java could...|\n",
      "|  2|Logestic,regressi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c274ff36-8203-4f09-89b1-9a6f785cd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602e174a-6ce2-4468-ae34-eeeb33723220",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58d8394-748e-472c-882a-3e3b4fb4c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_token = udf(lambda words:len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379f0a17-6c09-4443-a4cf-8454ebae96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.transform(sen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1caf60b4-cb0a-42b9-bee4-67dd23d9b710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| Id|            sentence|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  1|I wish java could...|[i, wish, java, c...|\n",
      "|  2|Logestic,regressi...|[logestic,regress...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c56fd251-c578-4380-afdb-fdd356a7e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-----+\n",
      "| Id|            sentence|               words|token|\n",
      "+---+--------------------+--------------------+-----+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|    5|\n",
      "|  1|I wish java could...|[i, wish, java, c...|    7|\n",
      "|  2|Logestic,regressi...|[logestic,regress...|    1|\n",
      "+---+--------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.withColumn('token', count_token(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d58ed11-ba8b-41ee-8a03-f8f7e652bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_tokenized = reg_tokenizer.transform(sen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260dde38-de61-4a08-b185-65940a58bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-----+\n",
      "| Id|            sentence|               words|token|\n",
      "+---+--------------------+--------------------+-----+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|    5|\n",
      "|  1|I wish java could...|[i, wish, java, c...|    7|\n",
      "|  2|Logestic,regressi...|[logestic, regres...|    5|\n",
      "+---+--------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rg_tokenized.withColumn('token', count_token(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95828df4-8cf8-4ac0-940d-870e2a0443fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "233d5175-4dec-491f-b756-7a6e351f1181",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentenceDataframe = spark.createDataFrame([\n",
    "    (0, ['I', 'saw', 'the', 'green' , 'horse']),\n",
    "    (1, ['Mary', 'had', 'a', 'little', 'lamb'])]\n",
    "    ,['id', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fef56dea-0488-4dc5-8dbd-b174ce11c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|              tokens|\n",
      "+---+--------------------+\n",
      "|  0|[I, saw, the, gre...|\n",
      "|  1|[Mary, had, a, li...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceDataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24fa4039-51ba-42a4-bc57-6a0e3356e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filttered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10844ea6-0629-48de-90bc-0c9cc00d1c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|              tokens|           filttered|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|[I, saw, the, gre...| [saw, green, horse]|\n",
      "|  1|[Mary, had, a, li...|[Mary, little, lamb]|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover.transform(sentenceDataframe).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675f2fe7-2f2d-4d0b-89e5-553d09ff9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "wordDataFrame = spark.createDataFrame([\n",
    "    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n",
    "    (1, [\"I\", \"wish\", \"Java\", \"could\", \"use\", \"case\", \"classes\"]),\n",
    "    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"neat\"])\n",
    "], [\"id\", \"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8531a8e1-1c46-448d-8a89-2879610feb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = NGram(n=2, inputCol='words', outputCol='gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7990e52b-0d94-4b5c-94e9-869cac923cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+\n",
      "|gram                                                              |\n",
      "+------------------------------------------------------------------+\n",
      "|[Hi I, I heard, heard about, about Spark]                         |\n",
      "|[I wish, wish Java, Java could, could use, use case, case classes]|\n",
      "|[Logistic regression, regression models, models are, are neat]    |\n",
      "+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram.transform(wordDataFrame).select('gram').show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d74159bf-a642-4d34-842a-c00ddd9da3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, IDF, HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "554b1f9d-4711-4a70-8898-72e17acbad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencedata = spark.createDataFrame([(0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f8cc954-72fa-4c61-bad8-192db4d91c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            sentence|\n",
      "+-----+--------------------+\n",
      "|  0.0|Hi I heard about ...|\n",
      "|  0.0|I wish Java could...|\n",
      "|  1.0|Logistic regressi...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentencedata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "085dd52f-2347-4b81-8543-04c3645c10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_Sen = Tokenizer(inputCol='sentence', outputCol='words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c169a2b2-84b1-4efa-92a1-1a440b6cf831",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sen = token_Sen.transform(sentencedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc21f285-4920-4c76-8071-f737bf88f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------+------------------------------------------+-----+\n",
      "|label|sentence                           |words                                     |count|\n",
      "+-----+-----------------------------------+------------------------------------------+-----+\n",
      "|0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |5    |\n",
      "|0.0  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7    |\n",
      "|1.0  |Logistic regression models are neat|[logistic, regression, models, are, neat] |5    |\n",
      "+-----+-----------------------------------+------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_sen.withColumn('count', count_token(col('words'))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bd5eb41-e0ec-489b-a39f-5d90e1a87393",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing = HashingTF(inputCol='words', outputCol='rawfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cada245-c803-492a-a659-509e80e01361",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_word = hashing.transform(tokenized_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18b822e0-6ddd-4ea2-afc1-3a7599fcff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|            sentence|               words|         rawfeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(262144,[18700,19...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|(262144,[19036,20...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|(262144,[46243,58...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashing_word.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8742de31-e431-4fd3-a2b9-3ae6108a022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='rawfeatures', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54adc986-69ed-4006-83b1-472549534cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "idf_model = idf.fit(hashing_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca6970d2-4b03-4808-8bff-aa6c1eca56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentences = idf_model.transform(hashing_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63eaf6a9-efe5-45e5-abe3-c65fe98b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(262144,[18700,19...|\n",
      "|  0.0|(262144,[19036,20...|\n",
      "|  1.0|(262144,[46243,58...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 16:20:21 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/12/30 16:20:21 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/12/30 16:20:21 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
     ]
    }
   ],
   "source": [
    "final_sentences.select('label', 'features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6639e752-f3e2-4b11-a6c6-a5a98173afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b5a6f54-e5b1-4b70-8dfe-d2065c5b6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(0, \"a b c\".split(\" \")),\n",
    "    (1, \"a b b c a\".split(\" \"))\n",
    "], [\"id\", \"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "954c9118-72d8-4736-9c9a-6adf997df145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|          words|\n",
      "+---+---------------+\n",
      "|  0|      [a, b, c]|\n",
      "|  1|[a, b, b, c, a]|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3ef9893-5250-4d66-a33e-1ed7e347d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countV = CountVectorizer(inputCol='words', outputCol='features', maxDF=2.0, vocabSize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2592a9f9-c029-447f-91ba-4c8ddad96a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countV_model = countV.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9626ebca-c5e7-4caa-ab85-715fcbed85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "countV_result = countV_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb5cbc16-9405-4774-93d6-6f0dbc76f05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-------------------------+\n",
      "|id |words          |features                 |\n",
      "+---+---------------+-------------------------+\n",
      "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n",
      "+---+---------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countV_result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc651061-4266-4dad-8ad7-b40884ec05e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
